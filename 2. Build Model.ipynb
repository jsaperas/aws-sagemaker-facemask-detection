{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb939012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, \"object-detection\", repo_version=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c64ec0",
   "metadata": {},
   "source": [
    "### Upload Augmented Manifest files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8336ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-facemasks-object-detection'\n",
    "prefix = 'facemask-detection'\n",
    "\n",
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + \"/train\"\n",
    "validation_channel = prefix + \"/validation\"\n",
    "\n",
    "sess.upload_data(path=\"training/augmented.manifest\", bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path=\"validation/augmented.manifest\", bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = \"s3://{}/{}/augmented.manifest\".format(bucket, train_channel)\n",
    "s3_validation_data = \"s3://{}/{}/augmented.manifest\".format(bucket, validation_channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b882bd",
   "metadata": {},
   "source": [
    "### Define Training Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/x-recordio\",\n",
    "    s3_data_type=\"AugmentedManifestFile\",\n",
    "    attribute_names=['source-ref', 'bounding-box'],\n",
    "    record_wrapping='RecordIO'\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"application/x-recordio\",\n",
    "    s3_data_type=\"AugmentedManifestFile\",\n",
    "    attribute_names=['source-ref', 'bounding-box'],\n",
    "    record_wrapping='RecordIO'\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_records(local_path):\n",
    "    with open(local_path, 'r') as f:\n",
    "        records = f.readlines()\n",
    "    return [json.loads(lb) for lb in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = get_training_records('training/augmented.manifest')\n",
    "max([len(lb['bounding-box']['annotations']) for lb in train_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76debc5",
   "metadata": {},
   "source": [
    "### Estimater and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779adbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_model = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    input_mode=\"Pipe\",\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "num_classes = 3\n",
    "num_epochs = 100\n",
    "lr_steps = \"33,67\" #reduce `learning_rate` by `lr_scheduler_factor` at epoch `33` and `67`\n",
    "num_training_samples = len(get_training_records('training/augmented.manifest'))\n",
    "\n",
    "od_model.set_hyperparameters(\n",
    "    base_network=\"resnet-50\",\n",
    "    use_pretrained_model=1,\n",
    "    num_classes=num_classes,\n",
    "    mini_batch_size=16,\n",
    "    epochs=num_epochs,\n",
    "    learning_rate=0.001,\n",
    "    #lr_scheduler_step=lr_steps,\n",
    "    lr_scheduler_factor=0.1,\n",
    "    optimizer=\"adam\",\n",
    "    momentum=0.9,\n",
    "    #weight_decay=0.0005,\n",
    "    #overlap_threshold=0.5,\n",
    "    #nms_threshold=0.45,\n",
    "    num_training_samples=num_training_samples,\n",
    "    label_width=115*5 + 4 ## Required = For example, if one image in the data contains at most 10 objects, and each object's annotation is specified with 5 numbers, [class_id, left, top, width, height], then the label_width should be no smaller than (10*5 + header information length). The header information length is usually 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781721f",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc048e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "od_model.fit(inputs=data_channels, logs='All')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
